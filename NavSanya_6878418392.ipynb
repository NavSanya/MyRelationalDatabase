{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NavSanya/MyRelationalDatabase/blob/main/NavSanya_6878418392.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTIul429gJtg"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20551ec1"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "import cmd\n",
        "import argparse\n",
        "import os\n",
        "import math\n",
        "import traceback\n",
        "# os.chdir('/content/drive/Shareddrives/USC_DSCI551-  Foundation of Data Management/Project') # where the files for this project are"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "221abc89"
      },
      "outputs": [],
      "source": [
        "# Function to copy selected columns from source CSV to a new CSV\n",
        "def copyColumns(sourceCsvFile, destinationCsvFile, columnsToCopy):\n",
        "    try:\n",
        "        with open(sourceCsvFile, 'r', newline='', encoding='utf-8') as source_file:\n",
        "            reader = csv.DictReader(source_file)\n",
        "            source_headers = reader.fieldnames\n",
        "\n",
        "            # Check if all columns to copy exist in the source CSV\n",
        "            for column in columnsToCopy:\n",
        "                if column not in source_headers:\n",
        "                    print(f\"Column '{column}' not found in the source CSV.\")\n",
        "                    return\n",
        "\n",
        "            with open(destinationCsvFile, 'w', newline='', encoding='utf-8') as dest_file:\n",
        "                writer = csv.DictWriter(dest_file, fieldnames=columnsToCopy)\n",
        "                writer.writeheader()\n",
        "\n",
        "                for row in reader:\n",
        "                    # Extract the desired columns\n",
        "                    selected_data = {col: str(row[col]) for col in columnsToCopy}\n",
        "                    writer.writerow(selected_data)\n",
        "\n",
        "\n",
        "        print(\"Selected columns copied to\", destinationCsvFile)\n",
        "        convert_csv_types(destinationCsvFile)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Source CSV file not found.\")\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", str(e))\n",
        "\n",
        "def convert_csv_types(fileName):\n",
        "    try:\n",
        "        with open(fileName, mode='r', newline='', encoding='utf-8') as input_csv_file:\n",
        "            reader = csv.reader(input_csv_file)\n",
        "\n",
        "            updatedData = []\n",
        "            header = next(reader)  # Read the header row\n",
        "            data_types = []  # List to store inferred data types for each column\n",
        "\n",
        "            for column in header:\n",
        "                if column.replace(\".\", \"\", 1).isdigit():\n",
        "                    data_types.append(float)\n",
        "                else:\n",
        "                    data_types.append(str)\n",
        "\n",
        "            for row in reader:\n",
        "                converted_row = []\n",
        "                for value, data_type in zip(row, data_types):\n",
        "                    if data_type == float:\n",
        "                        try:\n",
        "                            converted_item = float(value)\n",
        "                        except ValueError as e:\n",
        "                            print(f\"Value Error = {e}\")\n",
        "                            converted_item = None  # Keep it as a string for non-numeric values\n",
        "                    else:\n",
        "                        converted_item = value  # Keep it as a string\n",
        "                    converted_row.append(converted_item)\n",
        "                updatedData.append(converted_row)\n",
        "\n",
        "        with open(fileName, mode='w', newline='', encoding='utf-8') as output_csv_file:\n",
        "            writer = csv.writer(output_csv_file)\n",
        "            writer.writerow(header)  # Write the header row\n",
        "            writer.writerows(updatedData)\n",
        "\n",
        "        # print(f\"Data types converted and saved to {fileName}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{fileName}' not found.\")\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", str(e))\n",
        "\n",
        "\n",
        "# loading all the tables\n",
        "def createIndivisualTables():\n",
        "    # Essentials Table\n",
        "    copyColumns(\"IMDBTop250Movies.csv\", \"essentials.csv\",[\"rank\", \"name\", \"year\"])\n",
        "    copyColumns(\"IMDBTop250Movies.csv\", \"viewerDeets.csv\",[\"rank\", \"rating\", \"genre\", \"certificate\", \"run_time\", \"tagline\"])\n",
        "    copyColumns(\"IMDBTop250Movies.csv\", \"mediaDeets.csv\",[\"rank\", \"budget\", \"tagline\", \"box_office\"])\n",
        "    copyColumns(\"IMDBTop250Movies.csv\", \"makers.csv\",[\"rank\", \"casts\", \"directors\", \"writers\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fe021c0"
      },
      "outputs": [],
      "source": [
        "# createIndivisualTables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0458651"
      },
      "outputs": [],
      "source": [
        "class DatabaseFunctions:\n",
        "        #actual db model functions\n",
        "\n",
        "        def LoadCsvFile(self, fileName, chunkSize = 10):\n",
        "            convert_csv_types(fileName)\n",
        "            table = []\n",
        "            with open(fileName, mode='r', newline='',  encoding='utf-8') as file:\n",
        "                reader = csv.reader(file)\n",
        "                header = next(reader, None)\n",
        "                if header:\n",
        "                    for row in reader:\n",
        "                        data = {header[i]: value for i, value in enumerate(row)}\n",
        "                        converted_dict = {}\n",
        "\n",
        "                        for key, value in data.items():\n",
        "                            try:\n",
        "                                # Try to convert to int\n",
        "                                converted_value = int(value)\n",
        "                            except ValueError:\n",
        "                                try:\n",
        "                                    # If not an int, try to convert to float\n",
        "                                    converted_value = float(value)\n",
        "                                except ValueError:\n",
        "                                    # If it can't be converted to a number, keep it as a string\n",
        "                                    converted_value = value\n",
        "\n",
        "                            converted_dict[key] = converted_value\n",
        "                        table.append(converted_dict)\n",
        "\n",
        "                        if len(table) >= chunkSize:\n",
        "                            yield table # yeild the chunk of data\n",
        "                            table = [] # reset table for the next chunk\n",
        "                else:\n",
        "                    table = list(reader)\n",
        "            # print(*table, sep = '\\n')\n",
        "            yield table\n",
        "            file.close()\n",
        "            # return table\n",
        "\n",
        "        #CREATE TABLE\n",
        "        def createTable(self, table_name, columns):\n",
        "            fileName = str(table_name) + \".csv\"\n",
        "            try:\n",
        "                with open(fileName, mode='w', newline='', encoding='utf-8') as file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow(columns)\n",
        "                    print(f\"Table \\'{table_name}\\' created.\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"File '{fileName}' not found\")\n",
        "            except Exception as e:\n",
        "                print(\"An error occurred:\", str(e))\n",
        "\n",
        "        #INSERT INTO\n",
        "        def insertInto(self, table_name, columns, values):\n",
        "            fileName = str(table_name) + \".csv\"\n",
        "            data = [dict(zip(columns, values))]\n",
        "            try:\n",
        "                with open(fileName, \"a\", newline=\"\", encoding='utf-8') as f:\n",
        "                    for row in data:\n",
        "                        row_string = \",\".join([row[column] for column in columns])\n",
        "                        f.write(row_string + \"\\n\")\n",
        "\n",
        "                    convert_csv_types(fileName)\n",
        "                    print(f\"Data inserted into {table_name}\")\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Table '{table_name}' not found. Creating the table...\")\n",
        "                # Create the table with the provided columns\n",
        "                self.createTable(table_name, columns)\n",
        "                # Retry the insertion\n",
        "                self.insertInto(table_name, columns, values)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(\"An error occurred:\", str(e))\n",
        "                traceback.print_exc()\n",
        "\n",
        "        #GET FROM WHERE\n",
        "        def get(self, table_name, columns, condition):\n",
        "            fileName = f\"{table_name}.csv\"\n",
        "            try:\n",
        "                filtered_table = []\n",
        "                i = 1\n",
        "                for data in self.LoadCsvFile(fileName, 50):\n",
        "                    if data == []:\n",
        "                        break\n",
        "                    print(f\"Chunk {i} processing\")\n",
        "                    i+=1\n",
        "                    header = list(data[0].keys())\n",
        "                    if columns == [None]:\n",
        "                        columns = header\n",
        "                    for row in data:\n",
        "                        if eval(condition, row):\n",
        "                            filtered_table.append({column: row[column] for column in columns})\n",
        "                    print(*filtered_table, sep='\\n')\n",
        "                return filtered_table\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Table '{table_name}' not found.\")\n",
        "            except Exception as e:\n",
        "                print(\"An error occurred:\", str(e))\n",
        "                traceback.print_exc()\n",
        "\n",
        "        # show table\n",
        "        def displayTable(self, table_name):\n",
        "            fileName = str(table_name) + \".csv\"\n",
        "            data = self.LoadCsvFile(fileName)\n",
        "            data = data[:10]\n",
        "            print(*data, sep=\"\\n\")\n",
        "\n",
        "        # JOIN\n",
        "        def joinTable(self, table1_name, table2_name, commonColumns):\n",
        "            fileName1 = str(table1_name) + \".csv\"\n",
        "            fileName2 = str(table2_name) + \".csv\"\n",
        "\n",
        "            try:\n",
        "                joinedData = []\n",
        "                i = 1\n",
        "                j = 1\n",
        "                # Load table1 data in chunks\n",
        "                for chunk1 in self.LoadCsvFile(fileName1, 50):\n",
        "                    print(f\"Chunk {i} of {table1_name} processing\")\n",
        "                    i+=1\n",
        "                    # Load table2 data in chunks\n",
        "                    for chunk2 in self.LoadCsvFile(fileName2, 50):\n",
        "                        print(f\"Chunk {j} of {table2_name} processing\")\n",
        "                        j+=1\n",
        "                        # Perform join operation for each chunk pair\n",
        "                        chunkJoinedData = []\n",
        "                        # Join rows from table1 with matching rows from table2\n",
        "                        for row1 in chunk1:\n",
        "                            match = False\n",
        "                            for row2 in chunk2:\n",
        "                                match = True\n",
        "                                for key in commonColumns:\n",
        "                                    if row1.get(key) != row2.get(key):\n",
        "                                        match = False\n",
        "                                        break\n",
        "                                if match:\n",
        "                                    mergedRow = {**{f'{key}_{table1_name}': value for key, value in row1.items()},\n",
        "                                                **{f'{key}_{table2_name}': row2.get(key) for key in row2}}\n",
        "                                    chunkJoinedData.append(mergedRow)\n",
        "                                    break\n",
        "\n",
        "                        # Add unmatched rows from table1\n",
        "                        for row1 in chunk1:\n",
        "                            match = True\n",
        "                            for row2 in chunk2:\n",
        "                                for key in commonColumns:\n",
        "                                    if row1.get(key) != row2.get(key):\n",
        "                                        match = False\n",
        "                                        break\n",
        "                            if match:\n",
        "                                mergedRow = {**{f'{key}_{table1_name}': value for key, value in row1.items()},\n",
        "                                            **{f'{key}_{table2_name}': None for key in commonColumns}}\n",
        "                                chunkJoinedData.append(mergedRow)\n",
        "\n",
        "                        joinedData.extend(chunkJoinedData)\n",
        "\n",
        "                print(*joinedData, sep='\\n')\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Table(s) '{table1_name}' or '{table2_name}' not found.\")\n",
        "            except Exception as e:\n",
        "                print(\"An error occurred:\", str(e))\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "        # AGGREGATE FUNCTION\n",
        "        def aggregate(self, tablename, column, aggFunc, group_by=[]):\n",
        "          fileName1 = tablename + \".csv\"\n",
        "\n",
        "          try:\n",
        "              for chunk in self.LoadCsvFile(fileName1, 50):\n",
        "                if group_by:\n",
        "                    grouped_data = {}\n",
        "                    for row in chunk:\n",
        "                        key = tuple(row[col] for col in group_by)\n",
        "                        if key not in grouped_data:\n",
        "                            grouped_data[key] = []\n",
        "                        grouped_data[key].append(row[column])\n",
        "\n",
        "                    if aggFunc == \"SUM\":\n",
        "                        result = {key: sum(values) for key, values in grouped_data.items()}\n",
        "                    elif aggFunc == \"AVG\":\n",
        "                        result = {key: sum(values) / len(values) for key, values in grouped_data.items()}\n",
        "                    elif aggFunc == \"COUNT\":\n",
        "                        result = {key: len(values) for key, values in grouped_data.items()}\n",
        "                    elif aggFunc == \"MAX\":\n",
        "                        result = {key: max(values) for key, values in grouped_data.items()}\n",
        "                    elif aggFunc == \"MIN\":\n",
        "                        result = {key: min(values) for key, values in grouped_data.items()}\n",
        "                    else:\n",
        "                        print(f\"Unsupported aggregate function: {aggFunc}\")\n",
        "                        return None\n",
        "                    # print(result)\n",
        "                    yield result\n",
        "\n",
        "                else:\n",
        "                    actual_list = [row[column] for row in chunk]\n",
        "                    if actual_list == []:\n",
        "                        return\n",
        "                    if aggFunc == \"SUM\":\n",
        "                        result = sum(actual_list)\n",
        "                    elif aggFunc == \"AVG\":\n",
        "                        result = sum(actual_list) / len(actual_list)\n",
        "                    elif aggFunc == \"COUNT\":\n",
        "                        result = len(actual_list)\n",
        "                    elif aggFunc == \"MAX\":\n",
        "                        result = max(actual_list)\n",
        "                    elif aggFunc == \"MIN\":\n",
        "                        result = min(actual_list)\n",
        "                    else:\n",
        "                        print(f\"Unsupported aggregate function: {aggFunc}\")\n",
        "                        return None\n",
        "                    # print(result)\n",
        "                    yield result\n",
        "\n",
        "          except FileNotFoundError:\n",
        "              print(f\"Table '{tablename}' not found.\")\n",
        "          except Exception as e:\n",
        "              print(\"An error occurred:\", str(e))\n",
        "              import traceback\n",
        "              traceback.print_exc()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d33c9250"
      },
      "outputs": [],
      "source": [
        "class QueryLanguageProcessing:\n",
        "    def __init__(self):\n",
        "        self.inputQuery = \"\"\n",
        "        self.variables = []\n",
        "\n",
        "    def getCondition(self, strCondition):\n",
        "        # Define mapping of words to symbols\n",
        "        word_to_symbol = {\n",
        "            'is greater than': '>',\n",
        "            'is less than': '<',\n",
        "            'is at least': '>=',\n",
        "            'is at most': '<=',\n",
        "            'is equal to': '==',\n",
        "            'and': 'and',\n",
        "            'or': 'or'\n",
        "        }\n",
        "\n",
        "        # Replace words with corresponding symbols\n",
        "        for word, symbol in word_to_symbol.items():\n",
        "            strCondition = strCondition.replace(word, symbol)\n",
        "\n",
        "        # Replace 'x' and 'y' with their respective variable names\n",
        "        strCondition = re.sub(r'\\bx\\b', 'x', strCondition)\n",
        "        strCondition = re.sub(r'\\by\\b', 'y', strCondition)\n",
        "\n",
        "        return strCondition\n",
        "\n",
        "    def processStatement(self, statement, chunkSize = None):\n",
        "\n",
        "        # regular expressions to match different parts of the statement\n",
        "        getPattern = r\"GET (.+) FROM TABLE (\\w+) (?:WHERE (.+))?\" #DONE\n",
        "        combineTablesPattern = r\"COMBINE TABLES (.+) ON (.+)\" #DONE\n",
        "        findAggrigateFuncPattern = r\"FIND (\\w+) OF COLUMN (.+) FROM TABLE (\\w+)\" # DONE\n",
        "        AddValuesIntoPattern = r\"ADD VALUES (.+) INTO TABLE (\\w+) IN COLUMN/S (.+)\" #DONE\n",
        "        CreateTablePattern = r\"CREATE A TABLE (.+) WITH THE FOLLOWING COLUMNS: (.+)\" #DONE\n",
        "        updatePattern = r\"UPDATE (.+) IN TABLE (.+) WITH (.+)\"\n",
        "        showTable = r\"SHOW TABLE (.+)\" #DONE\n",
        "\n",
        "        dbFuncObj = DatabaseFunctions()\n",
        "\n",
        "        #get colums statement\n",
        "        if re.match(getPattern, statement):\n",
        "            match = re.match(getPattern, statement)\n",
        "            columnNames = match.group(1).split(',')\n",
        "            table = match.group(2)\n",
        "            if match.group(3) is not None:\n",
        "                whereConditionStr = match.group(3)\n",
        "            else:\n",
        "                whereConditionStr = \"True\"\n",
        "            whereCondition = self.getCondition(whereConditionStr)\n",
        "            print(f\"Table Name = {table}, column name = {columnNames}, condition = {whereCondition}\")\n",
        "            # Process the SELECT statement here\n",
        "            if columnNames == ['ALL']:\n",
        "                result = dbFuncObj.get(table_name=table, columns=[None], condition=whereCondition)\n",
        "            else:\n",
        "                result = dbFuncObj.get(table_name=table, columns=columnNames, condition=whereCondition)\n",
        "\n",
        "            print(*result, sep=\"\\n\")\n",
        "            # print(result)\n",
        "\n",
        "        #create table\n",
        "        elif re.match(CreateTablePattern, statement):\n",
        "            match = re.match(CreateTablePattern, statement)\n",
        "            table = match.group(1)\n",
        "            columns = match.group(2).split(\",\")\n",
        "            # Process the CREATE TABLE statement here\n",
        "            dbFuncObj.createTable(table,columns)\n",
        "\n",
        "        #combineTable\n",
        "        elif re.match(combineTablesPattern, statement):\n",
        "            match = re.match(combineTablesPattern, statement)\n",
        "            tableNames = match.group(1).split(',')\n",
        "            columnNames = match.group(2).split(',')\n",
        "            result = dbFuncObj.joinTable(tableNames[0], tableNames[1], columnNames)\n",
        "            print(*result, sep=\"\\n\")\n",
        "\n",
        "        #insert value\n",
        "        elif re.match(AddValuesIntoPattern, statement):\n",
        "            match = re.match(AddValuesIntoPattern, statement)\n",
        "            values = match.group(1).split(\",\")\n",
        "            tableName = match.group(2)\n",
        "            columnNames = match.group(3).split(\",\")\n",
        "            # Process the CREATE TABLE statement here\n",
        "            print(f\"Table name = {tableName} columns = {columnNames} values = {values}\")\n",
        "            dbFuncObj.insertInto(tableName, columnNames, values)\n",
        "\n",
        "        #aggrigate function\n",
        "        elif re.match(findAggrigateFuncPattern, statement):\n",
        "          match = re.match(findAggrigateFuncPattern, statement)\n",
        "          aggrigateFunc = match.group(1)\n",
        "          column = match.group(2)\n",
        "          tableName = match.group(3)\n",
        "          #process aggrigate statement here\n",
        "          print(f\"Aggrigate func = {aggrigateFunc} column = {column} table name = {tableName}\")\n",
        "          convert_csv_types(tableName + \".csv\")\n",
        "          result = dbFuncObj.aggregate(tableName, column, aggrigateFunc)\n",
        "          print(result)\n",
        "\n",
        "        #display table\n",
        "        elif re.match(showTable, statement):\n",
        "            match = re.match(showTable, statement)\n",
        "            tableName = match.group(1)\n",
        "            # Process the CREATE TABLE statement here\n",
        "            print(f\"Table name = {tableName}\")\n",
        "            dbFuncObj.displayTable(tableName)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SonnVRllnIQa"
      },
      "outputs": [],
      "source": [
        "# Create the CLI Interface\n",
        "class MyDbCLI(cmd.Cmd):\n",
        "        intro = \"Welcome to MyDB! Type 'help' to list commands or 'EXIT' to quit.\"\n",
        "        prompt = \"MyDB> \"\n",
        "        # dbfunc = DatabaseFunctions()\n",
        "        # queryObj = QueryLanguageProcessing()\n",
        "        def __init__(self) :\n",
        "            super().__init__()\n",
        "            self.dbfunc = DatabaseFunctions()\n",
        "            self.queryObj = QueryLanguageProcessing()\n",
        "\n",
        "        def default(self, line):\n",
        "          self.queryObj.processStatement(line)\n",
        "\n",
        "        def do_GET(self, line):\n",
        "          \"\"\"\n",
        "          It captures the columns to retrieve, the table name, and an optional WHERE condition for filtering the results.\n",
        "          SYNTAX:  GET <columns> FROM TABLE <table> WHERE <condition>\n",
        "                   GET ALL FROM TABLE <table> WHERE <condition>\n",
        "          EXAMPLE: GET column1,column2 FROM TABLE myTable\n",
        "                   GET ALL FROM TABLE employees WHERE department is equal to 'HR'\n",
        "\n",
        "          WHERE CONDITION LIST:\n",
        "                  greater than            | >\n",
        "                  less than               | <\n",
        "                  at least                | >=\n",
        "                  at most                 | <=\n",
        "                  equals                  | ==\n",
        "                  and                     | and\n",
        "                  or                      | or\n",
        "          \"\"\"\n",
        "          self.queryObj.processStatement(\"GET \" + str(line))\n",
        "\n",
        "        def do_COMBINE(self, line):\n",
        "          \"\"\"\n",
        "          This pattern is used to identify a command that combines two or more tables based on a specified column.\n",
        "          SYNTAX:  COMBINE TABLES <tables> ON <column_name>\n",
        "          EXAMPLE: COMBINE TABLES table1,table2 ON column\n",
        "          \"\"\"\n",
        "          self.queryObj.processStatement(\"COMBINE \" + str(line))\n",
        "\n",
        "        def do_FIND(self, line):\n",
        "          \"\"\"\n",
        "          This pattern is designed to identify a query that calculates an aggregate function (e.g., SUM, AVG, COUNT, MAX, MIN) on a specific column within a table.\n",
        "          SYNTAX:  FIND <aggregate_function> OF COLUMN <column> FROM TABLE <table>\n",
        "          EXAMPLE: FIND SUM OF COLUMN sales FROM TABLE sales_data\n",
        "          \"\"\"\n",
        "          self.queryObj.processStatement(\"FIND \" + str(line))\n",
        "\n",
        "        def do_ADD(self, line):\n",
        "          \"\"\"\n",
        "          This pattern captures a command for adding values into specified columns of a table.\n",
        "          SYNTAX:  ADD VALUES <values> INTO TABLE <table> IN COLUMN/S <columns>\n",
        "          EXAMPLE: ADD VALUES 'John',30 INTO TABLE employees IN COLUMNS 'name','age'\n",
        "          \"\"\"\n",
        "          self.queryObj.processStatement(\"ADD\" + str(line))\n",
        "\n",
        "        def do_CREATE(self, line):\n",
        "          \"\"\"\n",
        "          This pattern is used for creating a new table with a list of specified columns.\n",
        "          SYNTAX:  CREATE A TABLE <table> WITH THE FOLLOWING COLUMNS: <columns>\n",
        "          EXAMPLE: CREATE A TABLE products WITH THE FOLLOWING COLUMNS: product_id,product_name,price\n",
        "          \"\"\"\n",
        "          self.queryObj.processStatement(\"CREATE\" + str(line))\n",
        "\n",
        "        def do_SHOW(self, line):\n",
        "          \"\"\"\n",
        "          This pattern captures a command to display first 10 rows of a specific table\n",
        "          SYNTAX:  SHOW TABLE <table>\n",
        "          EXAMPLE: SHOW TABLE customers\n",
        "          \"\"\"\n",
        "          print(line)\n",
        "          self.queryObj.processStatement(\"SHOW \" + str(line))\n",
        "\n",
        "        def do_help(self, args):\n",
        "          \"\"\"\n",
        "          Display help for available commands.\n",
        "          Syntax: HELPME [<command_name>]\n",
        "          Example: HELPME CREATE\n",
        "          \"\"\"\n",
        "          if args:\n",
        "              try:\n",
        "                  command = getattr(self, f\"do_{args}\")\n",
        "                  print(command.__doc__)\n",
        "              except AttributeError:\n",
        "                  print(f\"Command '{args}' not found.\")\n",
        "          else:\n",
        "              super().do_help(args)\n",
        "\n",
        "        def do_exit(self, args):\n",
        "          \"\"\"\n",
        "          Exit the MyDB CLI!\n",
        "          \"\"\"\n",
        "          print(\"Exiting MyDB. Goodbye!\")\n",
        "          return True\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   myCliObj = MyDbCLI()\n",
        "#   myCliObj.cmdloop()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c95d0521",
        "outputId": "38a67fca-9b97-4fa1-998e-7789c0d4e448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125.5\n"
          ]
        }
      ],
      "source": [
        "#test dbfunctions\n",
        "\n",
        "dbfunc = DatabaseFunctions()\n",
        "# # list = islice(dbfunc.LoadCsvFile(\"makers.csv\"), 10)\n",
        "# # print(*list, sep=\"\\n\")\n",
        "\n",
        "# #create table - DONE\n",
        "# dbfunc.createTable(table_name=\"testTable\", columns=[\"a\",\"b\",\"c\"])\n",
        "\n",
        "# # insert into - DONE\n",
        "# dbfunc.insertInto(\"testTable\", [\"a\",\"b\", \"c\"], [\"2\", \"1.2\", \"yo\"])\n",
        "\n",
        "# # display Table - DONE\n",
        "# dbfunc.displayTable(\"makers\")\n",
        "\n",
        "# # get function - DONE\n",
        "# res = dbfunc.get(\"makers\", [\"rank\", \"directors\"], \"rank >= 90 and rank < 100\")\n",
        "# print(res)\n",
        "# print(*res, sep=\"\\n\")\n",
        "\n",
        "# # join - DONE\n",
        "# result = dbfunc.joinTable(\"testTable\", \"testTableQuery\", [\"a\", \"b\"])\n",
        "\n",
        "# aggregate - DONE\n",
        "result = dbfunc.aggregate(\"makers\", \"rank\", \"AVG\")\n",
        "res = list(result)\n",
        "print(sum(res)/len(res))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aac05809"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Test Statement processing of queries\n",
        "\n",
        "queryObj = QueryLanguageProcessing()\n",
        "\n",
        "# #getCondition\n",
        "# x = 10\n",
        "# y = 20\n",
        "# english_sentence = \"True\"\n",
        "# conditional_statement = queryObj.getCondition(english_sentence)\n",
        "# print(\"English Sentence:\", english_sentence)\n",
        "# print(\"Conditional Statement:\", conditional_statement)\n",
        "# print(eval(conditional_statement))\n",
        "\n",
        "# #get statement\n",
        "# statement = \"GET rank,writers FROM TABLE makers WHERE rank is greater than 0 and rank is less than 26\"\n",
        "# queryObj.processStatement(statement, chunkSize=50)\n",
        "# # print(*result, sep=\"\\n\")\n",
        "\n",
        "# # create Table\n",
        "# statement = \"CREATE A TABLE testTableQuery WITH THE FOLLOWING COLUMNS: a,b\"\n",
        "# result = queryObj.processStatement(statement)\n",
        "# # print(*result, sep=\"\\n\")\n",
        "\n",
        "# #get all statement\n",
        "# statement = \"GET ALL FROM TABLE mediaDeets WHERE budget is at least box_office\"\n",
        "# result = queryObj.processStatement(statement)\n",
        "# print(*result, sep=\"\\n\")\n",
        "\n",
        "# # AddValues\n",
        "# statement = \"ADD VALUES 1,2.1 INTO TABLE testTableQuery IN COLUMN/S a,b\"\n",
        "# result = queryObj.processStatement(statement)\n",
        "# print(result)\n",
        "\n",
        "# # ShowTable\n",
        "# statement = \"SHOW TABLE makers\"\n",
        "# queryObj.processStatement(statement)\n",
        "\n",
        "# # combineTable\n",
        "# statement = \"COMBINE TABLES testTable,testTableQuery ON a\"\n",
        "# queryObj.processStatement(statement)\n",
        "\n",
        "# # aggregate\n",
        "# statement = \"FIND COUNT OF COLUMN a FROM TABLE testTable\"\n",
        "# queryObj.processStatement(statement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTUVdqZWRyiS"
      },
      "outputs": [],
      "source": [
        "#EXTRAA CODE\n",
        "# def readCsvInChunks(self, filename, chunk_size=10):\n",
        "        #     with open(filename, 'r', encoding='utf-8') as csvfile:\n",
        "        #         # Read and store the header\n",
        "        #         header = csvfile.readline().strip().split(',')\n",
        "\n",
        "        #         # Initialize an empty set to track processed chunks\n",
        "        #         processed_chunks = set()\n",
        "\n",
        "        #         while True:\n",
        "        #             chunk = []\n",
        "        #             for _ in range(chunk_size):\n",
        "        #                 row = csvfile.readline().strip().split(',')\n",
        "        #                 if not row:\n",
        "        #                     break  # Break if end of file is reached\n",
        "\n",
        "        #                 chunk.append(row)\n",
        "\n",
        "        #             if chunk:\n",
        "        #                 # Check if the current chunk has already been processed\n",
        "        #                 chunk_hash = hash(tuple(tuple(row) for row in chunk))\n",
        "        #                 if chunk_hash in processed_chunks:\n",
        "        #                     # Skip processing the chunk if it's a repeat\n",
        "        #                     continue\n",
        "\n",
        "        #                 # Add the current chunk to the processed_chunks set\n",
        "        #                 processed_chunks.add(chunk_hash)\n",
        "\n",
        "        #                 yield header, chunk\n",
        "        #             else:\n",
        "        #                 break\n",
        "\n",
        "        # def LoadCsvFile(self, filename, chunk_size=10):\n",
        "        #     convert_csv_types(filename)\n",
        "        #     table = []\n",
        "\n",
        "        #     with open(filename, mode='r', newline='', encoding='utf-8') as file:\n",
        "        #         header, _ = file.readline().strip().split(','), None\n",
        "        #         print(\"########\")\n",
        "\n",
        "        #         if header:\n",
        "        #             for chunk in self.readCsvInChunks(file, chunk_size):\n",
        "        #                 for row in chunk:\n",
        "        #                     data = {header[i]: value for i, value in enumerate(row)}\n",
        "        #                     converted_dict = {}\n",
        "\n",
        "        #                     for key, value in data.items():\n",
        "        #                         try:\n",
        "        #                             # Try to convert to int\n",
        "        #                             converted_value = int(value)\n",
        "        #                         except ValueError:\n",
        "        #                             try:\n",
        "        #                                 # If not an int, try to convert to float\n",
        "        #                                 converted_value = float(value)\n",
        "        #                             except ValueError:\n",
        "        #                                 # If it can't be converted to a number, keep it as a string\n",
        "        #                                 converted_value = value\n",
        "\n",
        "        #                         converted_dict[key] = converted_value\n",
        "        #                     table.append(converted_dict)\n",
        "        #         else:\n",
        "        #             table = [line.strip().split(',') for line in file]\n",
        "\n",
        "        #     print(table)\n",
        "        #     return table\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#################### BEFORE CHUNKS #############################################################\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# import re\n",
        "# import csv\n",
        "# import cmd\n",
        "# import argparse\n",
        "# import os\n",
        "# import math\n",
        "# os.chdir('/content/drive/Shareddrives/USC_DSCI551-  Foundation of Data Management/Project') # where the files for this project are\n",
        "\n",
        "# # Function to copy selected columns from source CSV to a new CSV\n",
        "# def copyColumns(sourceCsvFile, destinationCsvFile, columnsToCopy):\n",
        "#     try:\n",
        "#         with open(sourceCsvFile, 'r', newline='', encoding='utf-8') as source_file:\n",
        "#             reader = csv.DictReader(source_file)\n",
        "#             source_headers = reader.fieldnames\n",
        "\n",
        "#             # Check if all columns to copy exist in the source CSV\n",
        "#             for column in columnsToCopy:\n",
        "#                 if column not in source_headers:\n",
        "#                     print(f\"Column '{column}' not found in the source CSV.\")\n",
        "#                     return\n",
        "\n",
        "#             with open(destinationCsvFile, 'w', newline='', encoding='utf-8') as dest_file:\n",
        "#                 writer = csv.DictWriter(dest_file, fieldnames=columnsToCopy)\n",
        "#                 writer.writeheader()\n",
        "\n",
        "#                 for row in reader:\n",
        "#                     # Extract the desired columns\n",
        "#                     selected_data = {col: str(row[col]) for col in columnsToCopy}\n",
        "#                     writer.writerow(selected_data)\n",
        "\n",
        "\n",
        "#         print(\"Selected columns copied to\", destinationCsvFile)\n",
        "#         convert_csv_types(destinationCsvFile)\n",
        "\n",
        "#     except FileNotFoundError:\n",
        "#         print(\"Source CSV file not found.\")\n",
        "#     except Exception as e:\n",
        "#         print(\"An error occurred:\", str(e))\n",
        "\n",
        "# def convert_csv_types(fileName):\n",
        "#     try:\n",
        "#         with open(fileName, mode='r', newline='', encoding='utf-8') as input_csv_file:\n",
        "#             reader = csv.reader(input_csv_file)\n",
        "\n",
        "#             updatedData = []\n",
        "#             header = next(reader)  # Read the header row\n",
        "#             data_types = []  # List to store inferred data types for each column\n",
        "\n",
        "#             for column in header:\n",
        "#                 if column.replace(\".\", \"\", 1).isdigit():\n",
        "#                     data_types.append(float)\n",
        "#                 else:\n",
        "#                     data_types.append(str)\n",
        "\n",
        "#             for row in reader:\n",
        "#                 converted_row = []\n",
        "#                 for value, data_type in zip(row, data_types):\n",
        "#                     if data_type == float:\n",
        "#                         try:\n",
        "#                             converted_item = float(value)\n",
        "#                         except ValueError as e:\n",
        "#                             print(f\"Value Error = {e}\")\n",
        "#                             converted_item = None  # Keep it as a string for non-numeric values\n",
        "#                     else:\n",
        "#                         converted_item = value  # Keep it as a string\n",
        "#                     converted_row.append(converted_item)\n",
        "#                 updatedData.append(converted_row)\n",
        "\n",
        "#         with open(fileName, mode='w', newline='', encoding='utf-8') as output_csv_file:\n",
        "#             writer = csv.writer(output_csv_file)\n",
        "#             writer.writerow(header)  # Write the header row\n",
        "#             writer.writerows(updatedData)\n",
        "\n",
        "#         # print(f\"Data types converted and saved to {fileName}\")\n",
        "\n",
        "#     except FileNotFoundError:\n",
        "#         print(f\"File '{fileName}' not found.\")\n",
        "#     except Exception as e:\n",
        "#         print(\"An error occurred:\", str(e))\n",
        "\n",
        "\n",
        "# # # loading all the tables\n",
        "# # def createIndivisualTables():\n",
        "# #     # Essentials Table\n",
        "# #     copyColumns(\"IMDBTop250Movies.csv\", \"essentials.csv\",[\"rank\", \"name\", \"year\"])\n",
        "# #     copyColumns(\"IMDBTop250Movies.csv\", \"viewerDeets.csv\",[\"rank\", \"rating\", \"genre\", \"certificate\", \"run_time\", \"tagline\"])\n",
        "# #     copyColumns(\"IMDBTop250Movies.csv\", \"mediaDeets.csv\",[\"rank\", \"budget\", \"tagline\", \"box_office\"])\n",
        "# #     copyColumns(\"IMDBTop250Movies.csv\", \"makers.csv\",[\"rank\", \"casts\", \"directors\", \"writers\"])\n",
        "\n",
        "\n",
        "# # createIndivisualTables()\n",
        "\n",
        "# class ChunkProcessor:\n",
        "#     def __init__(self, chunk_size=50):\n",
        "#         self.chunk_size = chunk_size\n",
        "\n",
        "#     def process_large_dataset(self, source_csv_file, query_columns):\n",
        "#         try:\n",
        "#             # Get the total number of rows in the dataset\n",
        "#             total_rows = sum(1 for line in open(source_csv_file, encoding='utf-8'))\n",
        "\n",
        "#             # Calculate the number of chunks based on the chunk size\n",
        "#             num_chunks = (total_rows // self.chunk_size) + 1\n",
        "\n",
        "#             with open(source_csv_file, 'r', newline='', encoding='utf-8') as csvfile:\n",
        "#                 # Initialize a CSV reader with chunk size\n",
        "#                 reader = csv.DictReader(csvfile)\n",
        "#                 fieldnames = reader.fieldnames\n",
        "\n",
        "#                 for i in range(num_chunks):\n",
        "#                     # Read a chunk of data\n",
        "#                     chunk = list(self.read_chunk(reader, fieldnames))\n",
        "\n",
        "#                     # Process each chunk independently\n",
        "#                     result_chunk = self.process_chunk(chunk, query_columns)\n",
        "\n",
        "#                     # Display or save the results of each chunk\n",
        "#                     self.display_result(result_chunk)\n",
        "\n",
        "#                     # Optional: Save the processed chunk to a new CSV file\n",
        "#                     self.save_result_to_csv(result_chunk, f'result_chunk_{i}.csv', fieldnames)\n",
        "\n",
        "#         except FileNotFoundError:\n",
        "#             print(f\"File '{source_csv_file}' not found.\")\n",
        "#         except Exception as e:\n",
        "#             print(\"An error occurred:\", str(e))\n",
        "\n",
        "#     def read_chunk(self, reader, fieldnames):\n",
        "#         for _ in range(self.chunk_size):\n",
        "#             try:\n",
        "#                 yield next(reader)\n",
        "#             except StopIteration:\n",
        "#                 break\n",
        "\n",
        "#     def process_chunk(self, chunk, query_columns):\n",
        "#         # Implement your query or processing logic here for each chunk\n",
        "#         # For demonstration, let's select specified columns from the chunk\n",
        "#         result_chunk = [{col: row[col] for col in query_columns} for row in chunk]\n",
        "#         return result_chunk\n",
        "\n",
        "#     def display_result(self, result_chunk):\n",
        "#         # Implement how you want to display the result for each chunk\n",
        "#         print(result_chunk)\n",
        "\n",
        "#     def save_result_to_csv(self, result_chunk, output_filename, fieldnames):\n",
        "#         # Implement how you want to save the result to a new CSV file for each chunk\n",
        "#         with open(output_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "#             writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "#             writer.writeheader()\n",
        "#             writer.writerows(result_chunk)\n",
        "#         print(f\"Result saved to {output_filename}\")\n",
        "\n",
        "\n",
        "# class DatabaseFunctions:\n",
        "#         #actual db model functions\n",
        "#         def LoadCsvFile(self, fileName):\n",
        "#             convert_csv_types(fileName)\n",
        "#             table = []\n",
        "#             with open(fileName, mode='r', newline='',  encoding='utf-8') as file:\n",
        "#                 reader = csv.reader(file)\n",
        "#                 header = next(reader, None)\n",
        "#                 if header:\n",
        "#                     for row in reader:\n",
        "#                         data = {header[i]: value for i, value in enumerate(row)}\n",
        "#                         converted_dict = {}\n",
        "\n",
        "#                         for key, value in data.items():\n",
        "#                             try:\n",
        "#                                 # Try to convert to int\n",
        "#                                 converted_value = int(value)\n",
        "#                             except ValueError:\n",
        "#                                 try:\n",
        "#                                     # If not an int, try to convert to float\n",
        "#                                     converted_value = float(value)\n",
        "#                                 except ValueError:\n",
        "#                                     # If it can't be converted to a number, keep it as a string\n",
        "#                                     converted_value = value\n",
        "\n",
        "#                             converted_dict[key] = converted_value\n",
        "#                         table.append(converted_dict)\n",
        "#                 else:\n",
        "#                     table = list(reader)\n",
        "#             print(table)\n",
        "#             file.close()\n",
        "#             return table\n",
        "\n",
        "#         #CREATE TABLE\n",
        "#         def createTable(self, table_name, columns):\n",
        "#             fileName = str(table_name) + \".csv\"\n",
        "#             try:\n",
        "#                 with open(fileName, mode='w', newline='', encoding='utf-8') as file:\n",
        "#                     writer = csv.writer(file)\n",
        "#                     writer.writerow(columns)\n",
        "#                     print(f\"Table \\'{table_name}\\' created.\")\n",
        "#             except FileNotFoundError:\n",
        "#                 print(f\"File '{fileName}' not found\")\n",
        "#             except Exception as e:\n",
        "#                 print(\"An error occurred:\", str(e))\n",
        "\n",
        "#         #INSERT INTO\n",
        "#         def insertInto(self, table_name, columns, values):\n",
        "#             fileName = str(table_name) + \".csv\"\n",
        "#             try:\n",
        "#                 with open(fileName, mode='r', newline='', encoding='utf-8') as fileRead:\n",
        "#                     reader = csv.reader(fileRead)\n",
        "#                     currentData = list(reader)\n",
        "\n",
        "#                 # Find the column indices to insert data into\n",
        "#                 column_indices = [currentData[0].index(col) for col in columns]\n",
        "\n",
        "#                 # Create a new row with empty values for all columns\n",
        "#                 new_row = [''] * len(currentData[0])\n",
        "\n",
        "#                 # Populate the new row with the provided values in the specified columns\n",
        "#                 for col, val in zip(column_indices, values):\n",
        "#                     new_row[col] = val\n",
        "\n",
        "#                 # Append the new row to the existing data\n",
        "#                 currentData.append(new_row)\n",
        "\n",
        "#                 # Write the updated data back to the CSV file\n",
        "#                 with open(fileName, mode='w', newline='', encoding='utf-8') as fileWrite:\n",
        "#                     writer = csv.writer(fileWrite)\n",
        "#                     writer.writerows(currentData)\n",
        "#                 fileRead.close()\n",
        "#                 fileWrite.close()\n",
        "#                 convert_csv_types(fileName)\n",
        "#                 print(f\"Data inserted into {table_name}\")\n",
        "\n",
        "#             except FileNotFoundError:\n",
        "#                 print(f\"Table '{table_name}' not found. Creating the table...\")\n",
        "#                 # Create the table with the provided columns\n",
        "#                 self.createTable(table_name, columns)\n",
        "#                 # Retry the insertion\n",
        "#                 self.insertInto(table_name, columns, values)\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 print(\"An error occurred:\", str(e))\n",
        "\n",
        "\n",
        "#         #GET FROM WHERE\n",
        "#         def get(self, table_name, columns, condition):\n",
        "#             fileName = f\"{table_name}.csv\"\n",
        "#             try:\n",
        "#                 selectedData = []\n",
        "#                 with open(fileName, mode='r', newline='', encoding='utf-8') as input_csv_file:\n",
        "#                     reader = csv.reader(input_csv_file)\n",
        "#                     header = next(reader)  # Read the header row\n",
        "#                     data_types = []  # List to store inferred data types for each column\n",
        "#                     row1 = next(reader)\n",
        "#                     for column in row1:\n",
        "#                         if column.isdigit():\n",
        "#                             data_types.append(int)\n",
        "#                         elif column.replace(\".\", \"\", 1).isdigit():\n",
        "#                             data_types.append(float)\n",
        "#                         else:\n",
        "#                             data_types.append(str)\n",
        "\n",
        "#                     # Read and convert data rows based on inferred data types\n",
        "#                     for row in reader:\n",
        "#                         converted_row = []\n",
        "#                         for value, data_type in zip(row, data_types):\n",
        "#                             if data_type == int:\n",
        "#                                 try:\n",
        "#                                     converted_row.append(int(value,20))\n",
        "#                                 except ValueError as e:\n",
        "#                                     converted_row.append(-1)  # Keep it as a string for non-numeric values\n",
        "\n",
        "#                             elif data_type == float:\n",
        "#                                 try:\n",
        "#                                     converted_row.append(float(value))\n",
        "#                                 except ValueError as e:\n",
        "#                                     converted_row.append(-1.0)\n",
        "\n",
        "#                             else:\n",
        "#                                 converted_row.append(value)\n",
        "\n",
        "#                         if columns == [None]:\n",
        "#                             columns = header\n",
        "#                         # Evaluate the condition and select rows that match\n",
        "#                         if condition:\n",
        "#                             if eval(condition, {}, dict(zip(header, converted_row))):\n",
        "#                                 selected_row = {column: value for column, value in zip(header, converted_row) if column in columns}\n",
        "#                                 selectedData.append(selected_row)\n",
        "#                 return selectedData\n",
        "\n",
        "#             except FileNotFoundError:\n",
        "#                 print(f\"Table '{table_name}' not found.\")\n",
        "#             except Exception as e:\n",
        "#                 print(\"An error occurred:\", str(e))\n",
        "\n",
        "#         # show table\n",
        "#         def displayTable(self, table_name):\n",
        "#             fileName = str(table_name) + \".csv\"\n",
        "#             data = self.LoadCsvFile(fileName)\n",
        "#             data = data[:10]\n",
        "#             print(*data, sep=\"\\n\")\n",
        "\n",
        "#         # JOIN\n",
        "#         def joinTable(self, table1_name, table2_name, commonColumns):\n",
        "#             fileName1 = str(table1_name) + \".csv\"\n",
        "#             fileName2 = str(table2_name) + \".csv\"\n",
        "\n",
        "#             try:\n",
        "#                 tableData1 = self.LoadCsvFile(fileName1)\n",
        "#                 tableData2 = self.LoadCsvFile(fileName2)\n",
        "#                 # Perform the join operation\n",
        "#                 joinedData = []\n",
        "#                 for row1 in tableData1:\n",
        "#                   for row2 in tableData2:\n",
        "#                     match = True\n",
        "#                     for key in commonColumns:\n",
        "#                       if row1.get(key) != row2.get(key):\n",
        "#                         match = False\n",
        "#                         break\n",
        "#                     if match:\n",
        "#                       mergedRow = {**{f'{key}_{table1_name}': value for key, value in row1.items()},\n",
        "#                         **{f'{key}_{table2_name}': row2.get(key) for key in row2}}\n",
        "#                       joinedData.append(mergedRow)\n",
        "\n",
        "#                 return joinedData\n",
        "\n",
        "#             except FileNotFoundError:\n",
        "#                 print(f\"Table(s) '{table1_name}' or '{table2_name}' not found.\")\n",
        "#             except Exception as e:\n",
        "#                 print(\"An error occurred:\", str(e))\n",
        "#                 import traceback\n",
        "#                 traceback.print_exc()\n",
        "\n",
        "#         # AGGREGATE FUNCTION\n",
        "#         def aggregate(self, tablename, column, aggFunc, group_by=[]):\n",
        "#           fileName1 = tablename + \".csv\"\n",
        "\n",
        "#           try:\n",
        "#               tableData = self.LoadCsvFile(fileName1)\n",
        "#               # print(tableData)\n",
        "#               if group_by:\n",
        "#                   print(\"Yes Goup by\")\n",
        "#                   grouped_data = {}\n",
        "#                   for row in tableData:\n",
        "#                       key = tuple(row[col] for col in group_by)\n",
        "#                       if key not in grouped_data:\n",
        "#                           grouped_data[key] = []\n",
        "#                       grouped_data[key].append(row[column])\n",
        "\n",
        "#                   if aggFunc == \"SUM\":\n",
        "#                       result = {key: sum(values) for key, values in grouped_data.items()}\n",
        "#                   elif aggFunc == \"AVG\":\n",
        "#                       result = {key: sum(values) / len(values) for key, values in grouped_data.items()}\n",
        "#                   elif aggFunc == \"COUNT\":\n",
        "#                       result = {key: len(values) for key, values in grouped_data.items()}\n",
        "#                   elif aggFunc == \"MAX\":\n",
        "#                       result = {key: max(values) for key, values in grouped_data.items()}\n",
        "#                   elif aggFunc == \"MIN\":\n",
        "#                       result = {key: min(values) for key, values in grouped_data.items()}\n",
        "#                   else:\n",
        "#                       print(f\"Unsupported aggregate function: {aggFunc}\")\n",
        "#                       return None\n",
        "\n",
        "#                   return result\n",
        "\n",
        "#               else:\n",
        "#                   actual_list = [row[column] for row in tableData]\n",
        "#                   if aggFunc == \"SUM\":\n",
        "#                     result = sum(actual_list)\n",
        "#                   elif aggFunc == \"AVG\":\n",
        "#                       result = sum(actual_list) / len(actual_list)\n",
        "#                   elif aggFunc == \"COUNT\":\n",
        "#                       result = len(actual_list)\n",
        "#                   elif aggFunc == \"MAX\":\n",
        "#                       result = max(actual_list)\n",
        "#                   elif aggFunc == \"MIN\":\n",
        "#                       result = min(actual_list)\n",
        "#                   else:\n",
        "#                       print(f\"Unsupported aggregate function: {aggFunc}\")\n",
        "#                       return None\n",
        "\n",
        "#                   return result\n",
        "\n",
        "#           except FileNotFoundError:\n",
        "#               print(f\"Table '{tablename}' not found.\")\n",
        "#           except Exception as e:\n",
        "#               print(\"An error occurred:\", str(e))\n",
        "#               import traceback\n",
        "#               traceback.print_exc()\n",
        "\n",
        "\n",
        "\n",
        "# class QueryLanguageProcessing:\n",
        "#     def __init__(self):\n",
        "#         self.inputQuery = \"\"\n",
        "#         self.variables = []\n",
        "\n",
        "#     def getCondition(self, strCondition):\n",
        "#         # Define mapping of words to symbols\n",
        "#         word_to_symbol = {\n",
        "#             'is greater than': '>',\n",
        "#             'is less than': '<',\n",
        "#             'is at least': '>=',\n",
        "#             'is greater than or equal to': '>=',\n",
        "#             'is at most': '<=',\n",
        "#             'is less than or equal to': '>=',\n",
        "#             'is equal to': '==',\n",
        "#             'and': 'and',\n",
        "#             'or': 'or'\n",
        "#         }\n",
        "\n",
        "#         # Replace words with corresponding symbols\n",
        "#         for word, symbol in word_to_symbol.items():\n",
        "#             strCondition = strCondition.replace(word, symbol)\n",
        "\n",
        "#         # Replace 'x' and 'y' with their respective variable names\n",
        "#         strCondition = re.sub(r'\\bx\\b', 'x', strCondition)\n",
        "#         strCondition = re.sub(r'\\by\\b', 'y', strCondition)\n",
        "\n",
        "#         return strCondition\n",
        "\n",
        "#     def processStatement(self, statement):\n",
        "\n",
        "#         # regular expressions to match different parts of the statement\n",
        "#         getPattern = r\"GET (.+) FROM TABLE (\\w+) (?:WHERE (.+))?\" #DONE\n",
        "#         combineTablesPattern = r\"COMBINE TABLES (.+) ON (.+)\" #DONE\n",
        "#         findAggrigateFuncPattern = r\"FIND (\\w+) OF COLUMN (.+) FROM TABLE (\\w+)\" # DONE\n",
        "#         AddValuesIntoPattern = r\"ADD VALUES (.+) INTO TABLE (\\w+) IN COLUMN/S (.+)\" #DONE\n",
        "#         CreateTablePattern = r\"CREATE A TABLE (.+) WITH THE FOLLOWING COLUMNS: (.+)\" #DONE\n",
        "#         updatePattern = r\"UPDATE (.+) IN TABLE (.+) WITH (.+)\"\n",
        "#         showTable = r\"SHOW TABLE (.+)\" #DONE\n",
        "\n",
        "#         dbFuncObj = DatabaseFunctions()\n",
        "\n",
        "#         #get colums statement\n",
        "#         if re.match(getPattern, statement):\n",
        "#             match = re.match(getPattern, statement)\n",
        "#             columnNames = match.group(1).split(',')\n",
        "#             table = match.group(2)\n",
        "#             if match.group(3) is not None:\n",
        "#                 whereConditionStr = match.group(3)\n",
        "#             else:\n",
        "#                 whereConditionStr = \"True\"\n",
        "#             whereCondition = self.getCondition(whereConditionStr)\n",
        "#             print(f\"Table Name = {table}, column name = {columnNames}, condition = {whereCondition}\")\n",
        "#             # Process the SELECT statement here\n",
        "#             if columnNames == ['ALL']:\n",
        "#               result = dbFuncObj.get(table_name=table, columns=[None], condition=whereCondition)\n",
        "#             else:\n",
        "#               result = dbFuncObj.get(table_name=table, columns=columnNames, condition=whereCondition)\n",
        "#             print(*result, sep=\"\\n\")\n",
        "\n",
        "#         #create table\n",
        "#         elif re.match(CreateTablePattern, statement):\n",
        "#             match = re.match(CreateTablePattern, statement)\n",
        "#             table = match.group(1)\n",
        "#             columns = match.group(2).split(\",\")\n",
        "#             # Process the CREATE TABLE statement here\n",
        "#             dbFuncObj.createTable(table,columns)\n",
        "\n",
        "#         #combineTable\n",
        "#         elif re.match(combineTablesPattern, statement):\n",
        "#             match = re.match(combineTablesPattern, statement)\n",
        "#             tableNames = match.group(1).split(',')\n",
        "#             columnNames = match.group(2).split(',')\n",
        "#             result = dbFuncObj.joinTable(tableNames[0], tableNames[1], columnNames)\n",
        "#             print(*result, sep=\"\\n\")\n",
        "\n",
        "#         #insert value\n",
        "#         elif re.match(AddValuesIntoPattern, statement):\n",
        "#             match = re.match(AddValuesIntoPattern, statement)\n",
        "#             values = match.group(1).split(\",\")\n",
        "#             tableName = match.group(2)\n",
        "#             columnNames = match.group(3).split(\",\")\n",
        "#             # Process the CREATE TABLE statement here\n",
        "#             print(f\"Table name = {tableName} columns = {columnNames} values = {values}\")\n",
        "#             dbFuncObj.insertInto(tableName, columnNames, values)\n",
        "\n",
        "#         #aggrigate function\n",
        "#         elif re.match(findAggrigateFuncPattern, statement):\n",
        "#           match = re.match(findAggrigateFuncPattern, statement)\n",
        "#           aggrigateFunc = match.group(1)\n",
        "#           column = match.group(2)\n",
        "#           tableName = match.group(3)\n",
        "#           #process aggrigate statement here\n",
        "#           print(f\"Aggrigate func = {aggrigateFunc} column = {column} table name = {tableName}\")\n",
        "#           convert_csv_types(tableName + \".csv\")\n",
        "#           result = dbFuncObj.aggregate(tableName, column, aggrigateFunc)\n",
        "#           print(result)\n",
        "\n",
        "#         #display table\n",
        "#         elif re.match(showTable, statement):\n",
        "#             match = re.match(showTable, statement)\n",
        "#             tableName = match.group(1)\n",
        "#             # Process the CREATE TABLE statement here\n",
        "#             print(f\"Table name = {tableName}\")\n",
        "#             dbFuncObj.displayTable(tableName)\n",
        "\n",
        "#         return \"Done\"\n",
        "\n",
        "# # Create the CLI Interface\n",
        "# class MyDbCLI(cmd.Cmd):\n",
        "#         intro = \"Welcome to MyDB! Type 'help' to list commands or 'EXIT' to quit.\"\n",
        "#         prompt = \"MyDB> \"\n",
        "#         # dbfunc = DatabaseFunctions()\n",
        "#         # queryObj = QueryLanguageProcessing()\n",
        "#         def __init__(self) :\n",
        "#             super().__init__()\n",
        "#             self.dbfunc = DatabaseFunctions()\n",
        "#             self.queryObj = QueryLanguageProcessing()\n",
        "\n",
        "#         def default(self, line):\n",
        "#           res = self.queryObj.processStatement(line)\n",
        "#           print(res)\n",
        "\n",
        "#         def do_GET(self, line):\n",
        "#           \"\"\"\n",
        "#           It captures the columns to retrieve, the table name, and an optional WHERE condition for filtering the results.\n",
        "#           SYNTAX:  GET <columns> FROM TABLE <table> WHERE <condition>\n",
        "#                    GET ALL FROM TABLE <table> WHERE <condition>\n",
        "#           EXAMPLE: GET column1,column2 FROM TABLE myTable\n",
        "#                    GET ALL FROM TABLE employees WHERE department is equal to 'HR'\n",
        "\n",
        "#           WHERE CONDITION LIST:\n",
        "#                   greater than            | >\n",
        "#                   less than               | <\n",
        "#                   at least                | >=\n",
        "#                   greater than equal to   | >=\n",
        "#                   greater than or equal to| >=\n",
        "#                   at most                 | <=\n",
        "#                   less than equal to      | <=\n",
        "#                   less than or equal to   | <=\n",
        "#                   equals                  | ==\n",
        "#                   equal to                | ==\n",
        "#           \"\"\"\n",
        "#           res = self.queryObj.processStatement(\"GET \" + str(line))\n",
        "#           print(res)\n",
        "\n",
        "#         def do_COMBINE(self, line):\n",
        "#           \"\"\"\n",
        "#           This pattern is used to identify a command that combines two or more tables based on a specified column.\n",
        "#           SYNTAX:  COMBINE TABLES <tables> ON <column_name>\n",
        "#           EXAMPLE: COMBINE TABLES table1,table2 ON column\n",
        "#           \"\"\"\n",
        "#           res = self.queryObj.processStatement(\"COMBINE \" + str(line))\n",
        "#           print(res)\n",
        "\n",
        "#         def do_FIND(self, line):\n",
        "#           \"\"\"\n",
        "#           This pattern is designed to identify a query that calculates an aggregate function (e.g., SUM, AVG, COUNT, MAX, MIN) on a specific column within a table.\n",
        "#           SYNTAX:  FIND <aggregate_function> OF COLUMN <column> FROM TABLE <table>\n",
        "#           EXAMPLE: FIND SUM OF COLUMN sales FROM TABLE sales_data\n",
        "#           \"\"\"\n",
        "#           res = self.queryObj.processStatement(\"FIND \" + str(line))\n",
        "#           print(res)\n",
        "\n",
        "#         def do_ADD(self, line):\n",
        "#           \"\"\"\n",
        "#           This pattern captures a command for adding values into specified columns of a table.\n",
        "#           SYNTAX:  ADD VALUES <values> INTO TABLE <table> IN COLUMN/S <columns>\n",
        "#           EXAMPLE: ADD VALUES 'John',30 INTO TABLE employees IN COLUMNS 'name','age'\n",
        "#           \"\"\"\n",
        "#           res = self.queryObj.processStatement(\"ADD\" + str(line))\n",
        "#           print(res)\n",
        "\n",
        "#         def do_CREATE(self, line):\n",
        "#           \"\"\"\n",
        "#           This pattern is used for creating a new table with a list of specified columns.\n",
        "#           SYNTAX:  CREATE A TABLE <table> WITH THE FOLLOWING COLUMNS: <columns>\n",
        "#           EXAMPLE: CREATE A TABLE products WITH THE FOLLOWING COLUMNS: product_id,product_name,price\n",
        "#           \"\"\"\n",
        "#           res = self.queryObj.processStatement(\"CREATE\" + str(line))\n",
        "#           print(res)\n",
        "\n",
        "#         def do_SHOW(self, line):\n",
        "#           \"\"\"\n",
        "#           This pattern captures a command to display first 10 rows of a specific table\n",
        "#           SYNTAX:  SHOW TABLE <table>\n",
        "#           EXAMPLE: SHOW TABLE customers\n",
        "#           \"\"\"\n",
        "#           print(line)\n",
        "#           res = self.queryObj.processStatement(\"SHOW \" + str(line))\n",
        "#           print(res)\n",
        "\n",
        "#         def do_help(self, args):\n",
        "#           \"\"\"\n",
        "#           Display help for available commands.\n",
        "#           Syntax: HELPME [<command_name>]\n",
        "#           Example: HELPME CREATE\n",
        "#           \"\"\"\n",
        "#           if args:\n",
        "#               try:\n",
        "#                   command = getattr(self, f\"do_{args}\")\n",
        "#                   print(command.__doc__)\n",
        "#               except AttributeError:\n",
        "#                   print(f\"Command '{args}' not found.\")\n",
        "#           else:\n",
        "#               super().do_help(args)\n",
        "\n",
        "#         def do_exit(self, args):\n",
        "#           \"\"\"\n",
        "#           Exit the MyDB CLI!\n",
        "#           \"\"\"\n",
        "#           print(\"Exiting MyDB. Goodbye!\")\n",
        "#           return True\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   myCliObj = MyDbCLI()\n",
        "#   myCliObj.cmdloop()\n",
        "\n",
        "\n",
        "\n",
        "# #test dbfunctions\n",
        "\n",
        "# dbfunc = DatabaseFunctions()\n",
        "# # # list = islice(dbfunc.LoadCsvFile(\"makers.csv\"), 10)\n",
        "# # # print(*list, sep=\"\\n\")\n",
        "\n",
        "# # #create table - DONE\n",
        "# # dbfunc.createTable(table_name=\"testTable\", columns=[\"a\",\"b\",\"c\"])\n",
        "\n",
        "# # # insert into - DONE\n",
        "# # dbfunc.insertInto(\"testTable\", [\"a\",\"b\", \"c\"], [\"2\", \"1.2\", \"yo\"])\n",
        "\n",
        "# # # display Table - DONE\n",
        "# # dbfunc.displayTable(\"makers\")\n",
        "\n",
        "# # # get function - DONE\n",
        "# # res = dbfunc.get(\"makers\", [\"rank\", \"directors\"], \"rank >= 90 and rank < 100\")\n",
        "# # print(res)\n",
        "# # # print(*res, sep=\"\\n\")\n",
        "\n",
        "# # # join - DONE\n",
        "# # result = dbfunc.joinTable(\"testTable\", \"testTableQuery\", [\"a\"])\n",
        "# # print(*result, sep=\"\\n\")\n",
        "\n",
        "# # # aggregate - DONE\n",
        "# # result = dbfunc.aggregate(\"testTable\", \"a\", \"AVG\")\n",
        "# # print(result)\n",
        "\n",
        "\n",
        "\n",
        "# # Test Statement processing of queries\n",
        "\n",
        "# queryObj = QueryLanguageProcessing()\n",
        "\n",
        "# # #getCondition\n",
        "# # x = 10\n",
        "# # y = 20\n",
        "# # english_sentence = \"True\"\n",
        "# # conditional_statement = queryObj.getCondition(english_sentence)\n",
        "# # print(\"English Sentence:\", english_sentence)\n",
        "# # print(\"Conditional Statement:\", conditional_statement)\n",
        "# # print(eval(conditional_statement))\n",
        "\n",
        "# # #get statement\n",
        "# # statement = \"GET rank,writers FROM TABLE makers WHERE rank is greater than 20 and rank is less than 25\"\n",
        "# # result = queryObj.processStatement(statement)\n",
        "# # print(*result, sep=\"\\n\")\n",
        "\n",
        "# # # create Table\n",
        "# # statement = \"CREATE A TABLE testTableQuery WITH THE FOLLOWING COLUMNS: a,b\"\n",
        "# # result = queryObj.processStatement(statement)\n",
        "# # # print(*result, sep=\"\\n\")\n",
        "\n",
        "# # #get all statement\n",
        "# # statement = \"GET ALL FROM TABLE mediaDeets WHERE budget is at least box_office\"\n",
        "# # result = queryObj.processStatement(statement)\n",
        "# # print(*result, sep=\"\\n\")\n",
        "\n",
        "# # # AddValues\n",
        "# # statement = \"ADD VALUES 1,2.1 INTO TABLE testTableQuery IN COLUMN/S a,b\"\n",
        "# # result = queryObj.processStatement(statement)\n",
        "# # print(result)\n",
        "\n",
        "# # # ShowTable\n",
        "# # statement = \"SHOW TABLE makers\"\n",
        "# # queryObj.processStatement(statement)\n",
        "\n",
        "# # # combineTable\n",
        "# # statement = \"COMBINE TABLES testTable,testTableQuery ON a\"\n",
        "# # queryObj.processStatement(statement)\n",
        "\n",
        "# # # aggregate\n",
        "# # statement = \"FIND COUNT OF COLUMN a FROM TABLE testTable\"\n",
        "# # queryObj.processStatement(statement)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3DV3QINRyiV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}